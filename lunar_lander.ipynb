{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrmse78sWJuxLy8Q9F0+mL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ystcHXOLAkdt"
      },
      "outputs": [],
      "source": [
        "! apt install swig cmake -q\n",
        "! pip install stable-baselines3==2.0.0a5 swig gymnasium[box2d] huggingface_sb3 -q\n",
        "! sudo apt-get update -q\n",
        "! apt install python3-opengl ffmpeg xvfb -q\n",
        "! pip3 install pyvirtualdisplay -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "bQLtn-lNDEu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub\n",
        "from huggingface_hub import notebook_login\n",
        "from stable_baselines3 import PPO, DQN, A2C\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor"
      ],
      "metadata": {
        "id": "pFHG0sOxDhSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "zenlfiTQb6CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "POLICY = \"MlpPolicy\""
      ],
      "metadata": {
        "id": "y2RGjc15GxCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proximal Policy Optimization (PPO)"
      ],
      "metadata": {
        "id": "yewDG_MU06s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_timesteps = 1000000\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "model = PPO(\n",
        "    policy=POLICY,\n",
        "    env=env,\n",
        "    n_steps=1024,\n",
        "    batch_size=32,\n",
        "    n_epochs=5,\n",
        "    gamma=0.999,\n",
        "    gae_lambda=0.98,\n",
        "    ent_coef=0.01,\n",
        "    verbose=0\n",
        "    )"
      ],
      "metadata": {
        "id": "lMJfZ1XL1AoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=total_timesteps, progress_bar=True)\n",
        "\n",
        "model_name = \"/content/ppo-LunarLander-v2\"\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "-CUopZpuKHs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "kZZ1e7_-KtDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"LunarLander-v2\"\n",
        "\n",
        "model_architecture = \"PPO\"\n",
        "\n",
        "repo_id = \"zypchn/ppo-Lunar-Lander\"\n",
        "\n",
        "commit_message = f\"Upload {env_id} with {model_architecture} trained agent\"\n",
        "\n",
        "eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode=\"rgb_array\"))])\n",
        "\n",
        "package_to_hub(\n",
        "    model=model,\n",
        "    model_name=model_name,\n",
        "    model_architecture=model_architecture,\n",
        "    env_id=env_id,\n",
        "    eval_env=eval_env,\n",
        "    repo_id=repo_id,\n",
        "    commit_message=commit_message\n",
        ")"
      ],
      "metadata": {
        "id": "6KpQ5B-PPEGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Q-Network (DQN)"
      ],
      "metadata": {
        "id": "tSj5WuFq1MrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_timesteps = 1000000\n",
        "env = gym.make(\"LunarLander-v2\")"
      ],
      "metadata": {
        "id": "Iuoefw_z6OdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DQN(\n",
        "    policy=POLICY,\n",
        "    env=env,\n",
        "    batch_size=128,\n",
        "    gamma=0.999,\n",
        "    learning_rate=3e-4,\n",
        "    learning_starts=1_000,\n",
        "    buffer_size=200_000,\n",
        "    exploration_final_eps=0.1,\n",
        "    exploration_fraction=0.3,\n",
        "    policy_kwargs=dict(net_arch=[256, 256]),\n",
        "    verbose=0\n",
        ")"
      ],
      "metadata": {
        "id": "64G_q0zCcW5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=total_timesteps, progress_bar=True)\n",
        "\n",
        "model_name = \"/content/dqn-LunarLander-v2\"\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "R4o6j0BO5GQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "iCa30vI959kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"LunarLander-v2\"\n",
        "\n",
        "model_architecture = \"DQN\"\n",
        "\n",
        "repo_id = \"zypchn/dqn-Lunar-Lander\"\n",
        "\n",
        "commit_message = f\"Upload {env_id} with {model_architecture} trained agent\"\n",
        "\n",
        "eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode=\"rgb_array\"))])\n",
        "\n",
        "package_to_hub(\n",
        "    model=model,\n",
        "    model_name=model_name,\n",
        "    model_architecture=model_architecture,\n",
        "    env_id=env_id,\n",
        "    eval_env=eval_env,\n",
        "    repo_id=repo_id,\n",
        "    commit_message=commit_message\n",
        ")"
      ],
      "metadata": {
        "id": "outjnsjbJR8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Actor-Critic (A2C)"
      ],
      "metadata": {
        "id": "-OqnB7PE1ybs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_timesteps = 1000000\n",
        "env = make_vec_env(\"LunarLander-v2\", n_envs=8)"
      ],
      "metadata": {
        "id": "DGSLBTHz8kbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C(\n",
        "    policy=POLICY,\n",
        "    env=env,\n",
        "    gamma=0.999,\n",
        "    gae_lambda=0.95,\n",
        "    n_steps=16,\n",
        "    ent_coef=0.05,\n",
        "    vf_coef=0.25,\n",
        "    max_grad_norm=0.5,\n",
        "    policy_kwargs=dict(net_arch=[256, 256]),\n",
        "    verbose=0\n",
        ")"
      ],
      "metadata": {
        "id": "z4BSgU4V22J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=total_timesteps, progress_bar=True)\n",
        "\n",
        "model_name = \"/content/a2c-LunarLander-v2\"\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "s_A_Oxny31tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "X5FSL3hK35S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"LunarLander-v2\"\n",
        "\n",
        "model_architecture = \"A2C\"\n",
        "\n",
        "repo_id = \"zypchn/a2c-Lunar-Lander\"\n",
        "\n",
        "commit_message = f\"Upload {env_id} with {model_architecture} trained agent\"\n",
        "\n",
        "eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode=\"rgb_array\"))])\n",
        "\n",
        "package_to_hub(\n",
        "    model=model,\n",
        "    model_name=model_name,\n",
        "    model_architecture=model_architecture,\n",
        "    env_id=env_id,\n",
        "    eval_env=eval_env,\n",
        "    repo_id=repo_id,\n",
        "    commit_message=commit_message\n",
        ")"
      ],
      "metadata": {
        "id": "XADoJDmw8rJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}